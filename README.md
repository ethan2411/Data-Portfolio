# Data-Portfolio
This is a repository of my personal data projects!
## Table of Contents
- [Excel Projects](#excel-projects)
- [PowerBI Projects](#powerbi-projects)
- [Python Projects](#python-projects)
- [SQL Projects](#sql-projects)
- [Tableau Projects](#tableau-projects)

## Excel Projects:
  ### [Bike Sales Analysis](https://github.com/ethan2411/Data-Portfolio/tree/main/Excel/Bike%20Sales%20Analysis):
      - Used Excel to clean data by removing duplicates, changing column formats, and adding columns to make data more usable.
      - Created pivot tables to make easy to read charts to display important information.
      - Created a dashboard with visualizations and slicers to gain additional insight into bike sales.
      
      
## PowerBI Projects:
  ### [Data Jobs Analysis](https://github.com/ethan2411/Data-Portfolio/tree/main/PowerBI/Data%20Jobs%20Exploration):
      - Dashboard created using Power BI for data analysis in the data field job market.
      - Visualizations including average salary by title and country, total number of participants, average age of participants, preferred programming languages, and happiness with salary and work/life balance.
      - Provides comprehensive insights on compensation trends, demographics, and satisfaction levels in the data field, offering valuable information for decision-makers and stakeholders.

## Python Projects:
  ### [Portfolio Diversification with K-Means, DBSCAN, and GMM Clustering](https://github.com/ethan2411/Data-Portfolio/blob/main/Python/Stock%20Clustering/Portfolio%20Divversification%20Based%20on%20Clusters.ipynb):
      - Conducted in-depth analysis of historical S&P 500 stock data, precisely quantifying annual returns and volatility.
      - Employed K-Means clustering, DBSCAN, and Gaussian Mixture Models (GMM) to reveal patterns in stock market data and engineer investment portfolios that balance risk and return.
      - Implemented the Elbow Method and Silhouette Method to determine the optimal number of clusters for K-Means clustering, leading to insightful insights into stock groupings.
      - Utilized DBSCAN, a density-based clustering algorithm, to detect clusters of varying shapes and sizes, enhancing portfolio selection strategies.
      - Leveraged Gaussian Mixture Models (GMM) to provide probabilistic clusters, adding a sophisticated layer to portfolio construction.
      - Constructed investment portfolios using insights from each clustering model, resulting in diversified stock selections tailored to different risk appetites.
      - Showcased advanced proficiency in Python (pandas, scikit-learn), expertly utilized for data analysis, visualization, and machine learning, elevating data-driven decision-making capabilities.
      
## SQL Projects:
  ### [Covid Data Exploration](https://github.com/ethan2411/Data-Portfolio/tree/main/SQL/Covid%20Data%20Exploration):
      - Performed data analysis on Covid-19 data from two datasets (CovidDeaths and CovidVaccinations).
      - Joined the two datasets to show the relationship between population, vaccinations, and deaths.
      - Created several views and queries to analyze Covid-19 data, including identifying countries with the highest infection and death rates.
      - Utilized techniques such as calculating percentages and cumulative sums, and employed Common Table Expressions (CTEs) and temporary tables in the data analysis.
      - Used Tableau to create a visual dashboard incorporating the insights gained from the SQL queries.
      - Developed interactive visualizations in Tableau to provide a comprehensive overview of Covid-19 data, including trend analysis, and geographical distributions across different countries.
      
  ### [Housing Data Cleaning](https://github.com/ethan2411/Data-Portfolio/tree/main/SQL/Housing%20Data%20Cleaning):
      - Developed SQL queries to identify and update missing property address data in a Nashville Housing dataset using COALESCE, SUBSTRING_INDEX, and LOCATE functions.
      - Separated property and owner address data into individual columns using ALTER TABLE, UPDATE, and TRIM functions to enable easier analysis of the dataset.
      - Updated inconsistent data values in the SoldAsVacant column using CASE and UPDATE functions to ensure data consistency.
      - Identified and deleted duplicate records using common table expressions (CTEs) and the DELETE function, improving data accuracy and reliability.
      - Utilized SQL queries to drop unused columns from the dataset using ALTER TABLE, improving database performance and storage efficiency.
   

## Tableau Projects:
  ### [Airbnb Analysis](https://public.tableau.com/app/profile/ethan2411/viz/AirbnbDashboard_16810667112040/Dashboard1):
      - Designed and developed a Tableau dashboard to analyze Seattle Airbnb data, enabling easy visualization of price trends by zipcode and number of bedrooms.
      - Used Tableau to create interactive charts and maps, allowing users to drill down into specific areas of interest and gain deeper insights into pricing patterns.
      - Leveraged Tableau's advanced analytics capabilities to identify key factors driving pricing variations, enabling more informed decision-making for both buyers and sellers in the Seattle Airbnb market.
      
  ### [Covid Data Exploration](https://public.tableau.com/app/profile/ethan2411/viz/CovidDashboard_16823938746140/Dashboard1):
      - Used Tableau to create a visual dashboard incorporating the insights gained from the SQL queries.
      - Developed interactive visualizations in Tableau to provide a comprehensive overview of Covid-19 data, including trend analysis, and geographical distributions across different countries.
      - Performed data analysis on Covid-19 data from two datasets (CovidDeaths and CovidVaccinations).
      - Joined the two datasets to show the relationship between population, vaccinations, and deaths.
      - Created several views and queries to analyze Covid-19 data, including identifying countries with the highest infection and death rates.
      - Utilized techniques such as calculating percentages and cumulative sums, and employed Common Table Expressions (CTEs) and temporary tables in the data analysis.
